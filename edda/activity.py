"""
Activity module for Edda framework.

This module provides the @activity decorator for defining atomic units of work
within workflows. Activities are the building blocks of Sagas and support
deterministic replay through result caching.
"""

import functools
import inspect
from collections.abc import Callable
from typing import Any, TypeVar, cast

from edda.context import WorkflowContext
from edda.pydantic_utils import (
    enum_value_to_enum,
    extract_enum_from_annotation,
    extract_pydantic_model_from_annotation,
    from_json_dict,
    to_json_dict,
)

F = TypeVar("F", bound=Callable[..., Any])


class Activity:
    """
    Wrapper class for activity functions.

    Handles execution, result caching during replay, and history recording.
    """

    def __init__(self, func: Callable[..., Any]):
        """
        Initialize activity wrapper.

        Args:
            func: The async function to wrap
        """
        self.func = func
        self.name = func.__name__
        functools.update_wrapper(self, func)

    async def __call__(self, ctx: WorkflowContext, *args: Any, **kwargs: Any) -> Any:
        """
        Execute the activity.

        During replay, returns cached result. During normal execution,
        executes the function and records the result.

        Args:
            ctx: Workflow context
            *args: Positional arguments for the activity
            **kwargs: Keyword arguments for the activity
                     Optional: activity_id (str) - Explicit activity ID
                     - Auto-generated by default (format: "{function_name}:{counter}")
                     - Manual specification required ONLY for concurrent execution
                       (asyncio.gather, async for, etc.)
                     - For sequential execution, rely on auto-generation

        Returns:
            Activity result

        Raises:
            Any exception raised by the activity function

        Example:
            Sequential execution (auto-generated IDs - recommended)::

                result1 = await my_activity(ctx, arg1)  # Auto: "my_activity:1"
                result2 = await my_activity(ctx, arg2)  # Auto: "my_activity:2"

            Concurrent execution (manual IDs - required)::

                results = await asyncio.gather(
                    my_activity(ctx, arg1, activity_id="my_activity:1"),
                    my_activity(ctx, arg2, activity_id="my_activity:2"),
                )
        """
        # Resolve activity ID (explicit or auto-generated)
        activity_id = self._resolve_id(ctx, kwargs.pop("activity_id", None))

        # Record activity ID execution
        ctx._record_activity_id(activity_id)

        # Call hook: activity start
        if ctx.hooks and hasattr(ctx.hooks, "on_activity_start"):
            await ctx.hooks.on_activity_start(ctx.instance_id, activity_id, self.name, ctx.is_replaying)

        # Check if workflow has been cancelled
        instance = await ctx._get_instance()
        if instance and instance.get("status") == "cancelled":
            from edda.exceptions import WorkflowCancelledException

            raise WorkflowCancelledException(f"Workflow {ctx.instance_id} has been cancelled")

        # Check if we're replaying and have a cached result
        if ctx.is_replaying:
            found, cached_result = ctx._get_cached_result(activity_id)
            if found:
                # Check if this was an error
                if isinstance(cached_result, dict) and cached_result.get("_error"):
                    # Reconstruct and raise the error
                    error_type = cached_result.get("error_type", "Exception")
                    error_message = cached_result.get("error_message", "Unknown error")

                    # Call hook: activity failed (from cache)
                    error_obj = Exception(f"{error_type}: {error_message}")
                    if ctx.hooks and hasattr(ctx.hooks, "on_activity_failed"):
                        await ctx.hooks.on_activity_failed(
                            ctx.instance_id, activity_id, self.name, error_obj
                        )

                    raise error_obj

                # Restore Pydantic model or Enum from cached result based on return type
                sig = inspect.signature(self.func)
                restored_result = cached_result

                # Check if return type is Pydantic model
                model = extract_pydantic_model_from_annotation(sig.return_annotation)
                if model is not None and isinstance(cached_result, dict):
                    restored_result = from_json_dict(cached_result, model)
                # Check if return type is Enum
                elif (
                    enum_class := extract_enum_from_annotation(sig.return_annotation)
                ) is not None:
                    from enum import Enum

                    if not isinstance(cached_result, Enum):
                        restored_result = enum_value_to_enum(cached_result, enum_class)

                # Call hook: activity complete (cache hit)
                if ctx.hooks and hasattr(ctx.hooks, "on_activity_complete"):
                    await ctx.hooks.on_activity_complete(
                        ctx.instance_id, activity_id, self.name, restored_result, cache_hit=True
                    )

                # Return cached successful result
                return restored_result

        # Execute activity in transaction for atomic operations
        # Note: If the activity fails, we record the failure OUTSIDE the transaction
        # to ensure the failure history is saved for observability
        try:
            async with ctx.transaction():
                return await self._execute_and_record(ctx, activity_id, args, kwargs)
        except Exception as error:
            # Activity failed - check if this is a cancellation exception
            from edda.exceptions import WorkflowCancelledException

            if isinstance(error, WorkflowCancelledException):
                # Re-raise cancellation without additional handling
                raise

            # For other exceptions, check if failure was already recorded
            # (it would have been recorded inside the transaction, but then rolled back)
            # We need to re-record it outside the transaction for observability

            # Capture input parameters for recording
            input_data = {
                "args": [to_json_dict(arg) for arg in args],
                "kwargs": {k: to_json_dict(v) for k, v in kwargs.items()},
            }

            # Record failure outside transaction (ensures it's saved)
            await ctx._record_activity_failed(activity_id, self.name, error, input_data)

            # Call hook: activity failed
            if ctx.hooks and hasattr(ctx.hooks, "on_activity_failed"):
                await ctx.hooks.on_activity_failed(ctx.instance_id, activity_id, self.name, error)

            # Re-raise the error
            raise

    async def _execute_and_record(
        self, ctx: WorkflowContext, activity_id: str, args: tuple[Any, ...], kwargs: dict[str, Any]
    ) -> Any:
        """
        Execute activity function and record the result.

        This helper method contains the core execution logic and is called
        within a transaction. If the activity fails, the exception is propagated
        and the transaction will be rolled back by the caller.

        Args:
            ctx: Workflow context
            activity_id: Activity ID
            args: Positional arguments for the activity
            kwargs: Keyword arguments for the activity

        Returns:
            Activity result

        Raises:
            Any exception raised by the activity function
        """
        # Capture input parameters for recording
        # Convert Pydantic models to JSON dicts for storage
        # args and kwargs contain the actual activity arguments (ctx is already passed separately)
        input_data = {
            "args": [to_json_dict(arg) for arg in args],
            "kwargs": {k: to_json_dict(v) for k, v in kwargs.items()},
        }

        # Execute the activity function
        result = await self.func(ctx, *args, **kwargs)

        # Convert Pydantic model result to JSON dict for storage
        result_for_storage = to_json_dict(result)

        # Record successful completion with input data
        # Always record when we actually execute, even during replay
        # (if we're here, it means there was no cached result)
        await ctx._record_activity_completed(activity_id, self.name, result_for_storage, input_data)

        # Auto-register compensation if @on_failure decorator is present
        if hasattr(self.func, "_compensation_func") and hasattr(self.func, "_has_compensation"):
            compensation_func = self.func._compensation_func

            # Merge activity result and input kwargs for compensation parameters
            # Convention: compensation function receives both input params and result values
            comp_kwargs = {**kwargs}  # Start with input kwargs

            # Add result values if result is a dict
            if isinstance(result, dict):
                comp_kwargs.update(result)

            # Register the compensation
            from edda.compensation import register_compensation

            await register_compensation(ctx, compensation_func, activity_id=activity_id, **comp_kwargs)

            print(f"[Activity] Auto-registered compensation: {compensation_func.__name__}")

        # Check if workflow was cancelled during activity execution
        instance = await ctx._get_instance()
        if instance and instance.get("status") == "cancelled":
            from edda.exceptions import WorkflowCancelledException

            raise WorkflowCancelledException(
                f"Workflow {ctx.instance_id} was cancelled during {self.name} execution"
            )

        # Call hook: activity complete (cache miss)
        if ctx.hooks and hasattr(ctx.hooks, "on_activity_complete"):
            await ctx.hooks.on_activity_complete(
                ctx.instance_id, activity_id, self.name, result, cache_hit=False
            )

        return result

    def _resolve_id(self, ctx: WorkflowContext, explicit_id: str | None) -> str:
        """
        Resolve activity ID (explicit or auto-generated).

        Args:
            ctx: Workflow context
            explicit_id: Explicitly provided activity ID (from kwargs)

        Returns:
            Resolved activity ID
        """
        if explicit_id is not None:
            return explicit_id

        # Auto-generate ID using context's generator
        return ctx._generate_activity_id(self.name)


def activity(func: F | None = None) -> F | Callable[[F], F]:
    """
    Decorator for defining activities (atomic units of work).

    Activities are async functions that take a WorkflowContext as the first
    parameter, followed by any other parameters.

    Activities are automatically wrapped in a transaction, ensuring that
    activity execution, history recording, and event sending are atomic.

    When using ctx.use_session() to share an external database session, the
    external session takes priority and all operations (activity execution,
    history recording, event sending) use that shared session, ensuring
    atomicity across your database and Edda's database.

    For non-idempotent operations (e.g., external API calls), place them in
    Activities to leverage result caching during replay. For operations that
    can be safely re-executed during replay, place them directly in the
    Workflow function.

    Example:
        >>> @activity
        ... async def reserve_inventory(ctx: WorkflowContext, order_id: str) -> dict:
        ...     # Your business logic here
        ...     return {"reservation_id": "123"}

        >>> @activity  # Works with ctx.use_session() for atomic operations
        ... async def process_payment(ctx: WorkflowContext, amount: float) -> dict:
        ...     session = AsyncSession(your_engine)
        ...     ctx.use_session(session)  # External session takes priority
        ...     # Your DB operations + Edda's operations = single transaction
        ...     # Edda automatically commits (or rolls back on exception)
        ...     return {"status": "completed"}

        >>> @activity  # Non-idempotent operations cached during replay
        ... async def charge_credit_card(ctx: WorkflowContext, amount: float) -> dict:
        ...     # External API call - result is cached, won't be called again on replay
        ...     return {"transaction_id": "txn_123"}

    Args:
        func: Async function to wrap as an activity

    Returns:
        Decorated function that can be called within a workflow
    """

    def decorator(f: F) -> F:
        # Verify the function is async
        if not inspect.iscoroutinefunction(f):
            raise TypeError(f"Activity {f.__name__} must be an async function")

        # Create the Activity wrapper
        activity_wrapper = Activity(f)

        # Mark as activity for introspection
        activity_wrapper._is_activity = True  # type: ignore[attr-defined]

        # Return the wrapper cast to the original type
        return cast(F, activity_wrapper)

    # Support @activity syntax (no parameters supported anymore)
    if func is None:
        # This should not happen anymore, but keep for compatibility
        return decorator
    else:
        # Called without arguments: @activity
        return decorator(func)
